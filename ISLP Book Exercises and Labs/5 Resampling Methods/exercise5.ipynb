{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58c6cf84-86f4-4c4d-80ce-1597b378fa35",
   "metadata": {},
   "source": [
    "# <span style=\"color: rgb(0, 105, 175);font-family: 'NewComputerModernMath';\">*Exercise Solutions*</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fe51b3-f27c-49a7-b325-121c85a7380d",
   "metadata": {},
   "source": [
    "## <span style=\"color: rgb(0, 105, 175);font-family: 'NewComputerModernMath';\">*Conceptual*</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff133940-2dce-4c43-b447-b29157a23ee9",
   "metadata": {},
   "source": [
    "### <span style=\"color: rgb(0, 105, 175);font-family: 'NewComputerModernMath';\">Q1</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ca4578-a145-4e4d-94c3-9e29bea5cb51",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*Using basic statistical properties of the variance, as well as single-variable calculus, derive <span style=\"color: rgb(0, 0, 255);\">(5.6)</span>. In other words, prove that $\\alpha$ given by <span style=\"color: rgb(0, 0, 255);\">(5.6)</span> does indeed minimize $\\text{Var}(\\alpha X + (1 - \\alpha) Y)$.*\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e53e7c-eb83-4dcc-a9f3-f13b5190000e",
   "metadata": {},
   "source": [
    "<span style=\"font-family: '';\">We will use following properties about variance\n",
    "\n",
    "$$\n",
    "Var(\\alpha X) = \\alpha^2 Var(X)\n",
    "$$\n",
    "\n",
    "$$\n",
    "Cov(\\alpha X,\\beta Y) = \\alpha \\beta Cov(X,Y)\n",
    "$$\n",
    "\n",
    "$$\n",
    "Var(\\alpha X + \\beta Y) = \\alpha^2 Var(X) + \\beta^2 Var(Y) + 2\\alpha \\beta Cov(X,Y)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "$$\n",
    "\\text{Var}(\\alpha X + (1 - \\alpha)Y) = \\alpha^2 \\sigma_X^2 + (1 - \\alpha)^2 \\sigma_Y^2 + 2\\alpha(1 - \\alpha)\\sigma_{XY},\n",
    "$$\n",
    "\n",
    "<span style=\"font-family: '';\">where \n",
    "\n",
    "$ \\sigma_X^2 = \\text{Var}(X) $, $ \\sigma_Y^2 = \\text{Var}(Y) $, and $ \\sigma_{XY} = \\text{Cov}(X, Y) $.</span>\n",
    "\n",
    "$$\n",
    "\\frac{d}{d\\alpha} \\text{Var}(\\alpha X + (1 - \\alpha)Y) = 2\\alpha\\sigma_X^2 - 2(1 - \\alpha)\\sigma_Y^2 + 2\\sigma_{XY}(1 - 2\\alpha).\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "<span style=\"font-family: '';\">Set the derivative to zero and solve for $ \\alpha $:</span>\n",
    "\n",
    "$$\n",
    "2\\alpha\\sigma_X^2 - 2(1 - \\alpha)\\sigma_Y^2 + 2\\sigma_{XY}(1 - 2\\alpha) = 0.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "<span style=\"font-family: '';\">Divide by 2:</span>\n",
    "\n",
    "$$\n",
    "\\alpha\\sigma_X^2 - (1 - \\alpha)\\sigma_Y^2 + \\sigma_{XY}(1 - 2\\alpha) = 0.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "<span style=\"font-family: '';\">Expand and collect terms:</span>\n",
    "\n",
    "$$\n",
    "\\alpha(\\sigma_X^2 + \\sigma_Y^2 - 2\\sigma_{XY}) = \\sigma_Y^2 - \\sigma_{XY}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "<span style=\"font-family: '';\">Solve for $ \\alpha $:</span>\n",
    "\n",
    "$$\n",
    "\\alpha = \\frac{\\sigma_Y^2 - \\sigma_{XY}}{\\sigma_X^2 + \\sigma_Y^2 - 2\\sigma_{XY}}. \\quad \\text{(Equation 5.6)}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "<span style=\"font-family: '';\">Verify the second derivative is positive:</span>\n",
    "\n",
    "$$\n",
    "\\frac{d^2}{d\\alpha^2} \\text{Var}(\\alpha X + (1 - \\alpha)Y) = 2\\sigma_X^2 + 2\\sigma_Y^2 - 4\\sigma_{XY}.\n",
    "$$\n",
    "\n",
    "<span style=\"font-family: '';\">This is positive if $ \\sigma_X^2 + \\sigma_Y^2 > 2\\sigma_{XY} $, ensuring the critical point is a minimum.</span>\n",
    "\n",
    "<span style=\"font-family: '';\">Conclusion: The value</span>\n",
    "\n",
    "$$\n",
    "\\alpha = \\frac{\\sigma_Y^2 - \\sigma_{XY}}{\\sigma_X^2 + \\sigma_Y^2 - 2\\sigma_{XY}}\n",
    "$$\n",
    "\n",
    "<span style=\"font-family: '';\">minimizes the variance of $ \\alpha X + (1 - \\alpha)Y $.</span>\n",
    "\n",
    "$$\n",
    "\\boxed{\\alpha = \\frac{\\text{Var}(Y) - \\text{Cov}(X,Y)}{\\text{Var}(X) + \\text{Var}(Y) - 2\\text{Cov}(X,Y)}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d6bc14-46c3-44e6-a5a4-0f9509893e82",
   "metadata": {},
   "source": [
    "### <span style=\"color: rgb(0, 105, 175);font-family: 'NewComputerModernMath';\">Q2</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186bd25c-481a-4a22-9e02-6deca989df27",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*We will now derive the probability that a given observation is part of a bootstrap sample. Suppose that we obtain a bootstrap sample from a set of $n$ observations.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69133a0-8084-4bf3-abda-9c08c12a9c2a",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*(a) What is the probability that the first bootstrap observation is **not** the $j$th observation from the original sample? Justify your answer.</span>*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efff29cb-13bf-4055-b104-49cdffa60675",
   "metadata": {},
   "source": [
    "<span style=\"font-family: '';\"> All observations have equal chance to be chosen. So,\n",
    "\n",
    "$$\n",
    "P(\\text{First bootstrap observation} = j \\mid n) = \\frac{1}{n}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(\\text{First bootstrap observation} \\neq j \\mid n) = 1 - P(\\text{First bootstrap observation} = j \\mid n) = 1 - \\frac{1}{n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84dcdba-6281-46bb-9a0f-2c3f03732b50",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*(b) What is the probability that the second bootstrap observation is **not** the $j$th observation from the original sample?</span>*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a4cdd2-4b67-452f-9bda-574cbd0c37f4",
   "metadata": {},
   "source": [
    "<span style=\"font-family: '';\"> Same question, doesn't matter which observation because all choices are independent\n",
    "\n",
    "$$\n",
    "P(\\text{Second bootstrap observation} = j \\mid n) = \\frac{1}{n}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(\\text{Second bootstrap observation} \\neq j \\mid n) = 1 - P(\\text{Second bootstrap observation} = j \\mid n) = 1 - \\frac{1}{n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c84f72-8441-4ec6-9048-368ee4a0cc28",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*(c) Argue that the probability that the $j$th observation is **not** in the bootstrap sample is $\\left(1 - \\frac{1}{n}\\right)^n$.</span>*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9ad0e9-5f5c-447a-862a-b2e932c6f7cf",
   "metadata": {},
   "source": [
    "<span style=\"font-family: '';\"> Since all choices are independent,\n",
    "\n",
    "$$\n",
    "P(\\text{ith bootstrap observation} \\neq j \\mid n) = 1 - \\frac{1}{n}\n",
    "$$\n",
    "\n",
    "<span style=\"font-family: '';\"> We multiply probabilities when they are independent\n",
    "\n",
    "$$\n",
    "P(\\text{jth observation is not in bootstrap} = P(\\text{1st bootstrap observation} \\neq j \\mid n) \\times P(\\text{2nd bootstrap observation} \\neq j \\mid n) \\times \\cdots P(\\text{nth bootstrap observation} \\neq j \\mid n)\n",
    "$$\n",
    "\n",
    "<span style=\"font-family: '';\"> Therefore,\n",
    "\n",
    "$$\n",
    "P(\\text{jth observation is not in bootstrap} = \\left( 1 - \\frac{1}{n} \\right)_1 \\times \\left( 1 - \\frac{1}{n} \\right)_2 \\times \\cdots \\left( 1 - \\frac{1}{n} \\right)_n = \\left( 1 - \\frac{1}{n} \\right)^n\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80f8012-78b4-4bf9-be85-aa681aafd058",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*(d) When $n = 5$, what is the probability that the $j$th observation is in the bootstrap sample?</span>*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5639dbba-8be1-4a95-b155-3171b7ad1bf1",
   "metadata": {},
   "source": [
    "$$\n",
    "1 - \\left( 1 - \\frac{1}{5} \\right)^5\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267f1864-46ff-41fe-9657-23cbb4607a67",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*(e) When $n = 100$, what is the probability that the $j$th observation is in the bootstrap sample?</span>*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f554f7-b752-4036-8a47-2dc3522dbc27",
   "metadata": {},
   "source": [
    "$$\n",
    "1 - \\left( 1 - \\frac{1}{100} \\right)^{100}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa35da7d-e11c-4c6a-a8ca-3d8158dbf441",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*(f) When $n = 10,000$, what is the probability that the $j$th observation is in the bootstrap sample?</span>*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f946f1d3-ab33-4ac3-b1bd-f2e2f2211feb",
   "metadata": {},
   "source": [
    "$$\n",
    "1 - \\left( 1 - \\frac{1}{10000} \\right)^{10000}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4565a802-984f-4ef5-8a3e-db87319978d9",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*(g) Create a plot that displays, for each integer value of $n$ from 1 to 100,000, the probability that the $j$th observation is in the bootstrap sample. Comment on what you observe.</span>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "bd736b47-8aed-4631-9a50-9941ab1c5653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.632138955406908\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x = np.arange(1,10000)\n",
    "y = 1 - (1-(1/x))**x\n",
    "\n",
    "plt.plot(x,y)\n",
    "print(y[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6829ec43-188f-468d-82e9-90c0ce67da79",
   "metadata": {},
   "source": [
    "<span style=\"font-family: '';\"> Since the observation will be chosen randomly and each observation has equal chance to be chosen, if number of observations are increased, then the probability of choosing a spesific value will decrease. Giving an example, the probability of getting 1 with a standard dice is $\\frac{1}{6}$ but if the dice has 20 sides, then the probability of getting 1 will be $\\frac{1}{20}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8bfd80-e021-4377-9105-818ecf0498ab",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*(h) We will now investigate numerically the probability that a bootstrap sample of size $n = 100$ contains the $j$th observation. Here $j = 4$. We first create an array <span style=\"color: rgb(145, 75, 40);\">store</span> with values that will subsequently be overwritten using the function <span style=\"color: rgb(145, 75, 40);\">np.empty()</span>. We then repeatedly create bootstrap samples, and each time we record whether or not the fifth observation is contained in the bootstrap sample.</span>*\n",
    "\n",
    "```python\n",
    "rng = np.random.default_rng(10)\n",
    "store = np.empty(10000)\n",
    "for i in range(10000):\n",
    "    store[i] = np.sum(rng.choice(100, replace=True) == 4) > 0\n",
    "np.mean(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18afc520-a354-41bf-a67d-addd68de2557",
   "metadata": {},
   "source": [
    "<span style=\"font-family: '';color: red;\">*Note*</span><span style=\"font-family: 'NewComputerModernMath';\">: When we run this code, we get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "49a39707-4d33-4997-83a5-294cd6c18c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0089"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng(10)\n",
    "store = np.empty(10000)\n",
    "for i in range(10000):\n",
    "    store[i] = np.sum(rng.choice(100, replace=True) == 4) > 0\n",
    "np.mean(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe86090-7cbc-4947-8d4c-52126130325f",
   "metadata": {},
   "source": [
    "<span style=\"font-family: '';\">As we can see that something is wrong. It should be approximately 0.63 but we get 0.0089. The reason is that it is forgotten that rng.choice function will produce ony one example. However we want to do check wheter sample with 100 observations include \"4\" or not and we want to do this experiment 10 000 times and getting the mean to be more accurate. To fix that, we can add \"size=100\" as a parameter. Such as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "c8bb1106-b234-455b-aa56-61651953c78f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6362"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng(10)\n",
    "store = np.empty(10000)\n",
    "for i in range(10000):\n",
    "    store[i] = np.sum(rng.choice(100, replace=True, size=100) == 4) > 0\n",
    "np.mean(store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "f59ee00b-300e-4628-a772-fcb45b5c90e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6339676587267709"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - (1-1/100)**100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7c90cb-9040-4dbb-9340-8e1225b47815",
   "metadata": {},
   "source": [
    "<span style=\"font-family: '';\"> Now, we can see that theorical result matches with applied result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdacea6-ae3b-49f3-93f5-3d995ad45826",
   "metadata": {},
   "source": [
    "### <span style=\"color: rgb(0, 105, 175);font-family: 'NewComputerModernMath';\">Q3</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ea68a0-6da2-45b7-a7ed-2934bcdf0d1f",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*We now review k-fold cross-validation.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d97f32-01e5-4b3d-a16b-43b286307096",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*(a) Explain how k-fold cross-validation is implemented.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6984f36d-c7bc-4492-9e83-6747bc8e9dcf",
   "metadata": {},
   "source": [
    "#####  <span style=\"font-family: 'NewComputerModernMath';\"> ***i.** Choose k*\n",
    "#####  <span style=\"font-family: 'NewComputerModernMath';\"> ***ii.** Split data into k random parts*\n",
    "#####  <span style=\"font-family: 'NewComputerModernMath';\"> ***iii.** Use k−1 folds for training, 1 fold for testing*\n",
    "#####  <span style=\"font-family: 'NewComputerModernMath';\"> ***iv.** Repeat the process k times to ensure each fold is used as test data*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9202fabc-3b34-4e79-91df-0ada47aa963a",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*(b) What are the advantages and disadvantages of k-fold cross-validation relative to: **i.** <span style=\"font-family: 'NewComputerModernMath';\"> The validation set approach? **ii.** <span style=\"font-family: 'NewComputerModernMath';\"> LOOCV?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4726eea9-6cac-46f2-a9bf-7e063b743792",
   "metadata": {},
   "source": [
    "##### <span style=\"font-family: 'NewComputerModernMath';\">*(b) Advantages and Disadvantages of $ k $-Fold Cross-Validation*\n",
    "\n",
    "| Method  | Advantages | Disadvantages |\n",
    "|---------|-----------|---------------|\n",
    "| **$ k $-Fold Cross-Validation** | - Uses multiple training/testing splits, leading to a more reliable estimate of model performance. <br> - Reduces variance compared to a single validation set. <br> - Utilizes data more efficiently since all data points contribute to training and validation. <br> - Less computationally expensive than LOOCV. | - Computationally more expensive than the validation set approach since the model is trained $ k $ times. <br> - More complex to implement compared to a simple validation split. |\n",
    "| **LOOCV (Leave-One-Out Cross-Validation)** | - Uses almost all data for training, leading to a **low bias** estimate. <br> - Provides the most **unbiased** estimate of test error. | - Computationally very expensive since it requires training the model $ n $ times. <br> - High variance due to training on nearly the entire dataset, which can lead to overfitting. |\n",
    "\n",
    "</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3980d973-f552-4f47-b1d9-7bd5a95eeccf",
   "metadata": {},
   "source": [
    "### <span style=\"color: rgb(0, 105, 175);font-family: 'NewComputerModernMath';\">Q4</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f20b92-9199-48db-a73d-38b64ca967bd",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*Suppose that we use some statistical learning method to make a prediction for the response Y for a particular value of the predictor X. Carefully describe how we might estimate the standard deviation of our prediction.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb2c14c-72ea-4d6e-9ebe-4698b52ff868",
   "metadata": {},
   "source": [
    "##### <span style=\"font-family: '';\"> We can use bootstrapping to calculate standard deviation of our model. The reason is that Finding new data is hard and expensive to choose as a method. A simple, fast and cheaper method to do is bootstrapping. We can create new datasets (generally, choosing 10 000 times) by using our current data set. Then we can apply training/testing pipeline and getting new predictions. After that, calculation of standard deviations by using acquired predictions can give us some insights about the population with an easy, cheap way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c45b314-2ddf-4f8e-966f-831616644c60",
   "metadata": {},
   "source": [
    "## <span style=\"color: rgb(0, 105, 175);font-family: 'NewComputerModernMath';\">*Applied*</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdacc42-6aa3-40de-b410-d4a1cee6a85c",
   "metadata": {},
   "source": [
    "### <span style=\"color: rgb(0, 105, 175);font-family: 'NewComputerModernMath';\">Q5</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da74cf3-6d95-45d5-a7f6-44ea3640712e",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*In Chapter 4, we used logistic regression to predict the probability of <span style=\"color: rgb(145, 75, 40);\">default</span> using <span style=\"color: rgb(145, 75, 40);\">income</span> and <span style=\"color: rgb(145, 75, 40);\">balance</span> on the <span style=\"color: rgb(145, 75, 40);\">Default</span> data set. We will now estimate the test error of this logistic regression model using the validation set approach. Do not forget to set a random seed before beginning your analysis.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c554e9-6789-4296-88c1-3b49112c95bc",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*(a) Fit a logistic regression model that uses <span style=\"color: rgb(145, 75, 40);\">income</span> and <span style=\"color: rgb(145, 75, 40);\">balance</span> to predict <span style=\"color: rgb(145, 75, 40);\">default</span>.</span>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "0dcf2f55-3fdc-4e4e-a8cc-6128954c448a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ISLP import load_data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns #visualization library\n",
    "from sklearn.linear_model import LogisticRegression #problem will be solved with scikit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis #linear discriminant analysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis #quadratic discriminant analysis\n",
    "from sklearn.neighbors import KNeighborsClassifier #K nearest neighbours (KNN)\n",
    "from sklearn. naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib .pyplot import subplots\n",
    "import statsmodels .api as sm\n",
    "from ISLP import load_data\n",
    "from ISLP.models import ( ModelSpec as MS , summarize)\n",
    "from ISLP import confusion_table\n",
    "from ISLP.models import contrast\n",
    "from sklearn. discriminant_analysis import \\\n",
    "( LinearDiscriminantAnalysis as LDA ,\n",
    "QuadraticDiscriminantAnalysis as QDA)\n",
    "\n",
    "import statsmodels.api as sm #to compute p-values\n",
    "from patsy import dmatrices\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "dcf680fa-3f80-4a4f-880f-71a29a32ce9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>711.555020</td>\n",
       "      <td>52992.378914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>757.962918</td>\n",
       "      <td>19660.721768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>845.411989</td>\n",
       "      <td>58636.156984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1569.009053</td>\n",
       "      <td>36669.112365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>200.922183</td>\n",
       "      <td>16862.952321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     default student      balance        income\n",
       "0         No      No   729.526495  44361.625074\n",
       "1         No     Yes   817.180407  12106.134700\n",
       "2         No      No  1073.549164  31767.138947\n",
       "3         No      No   529.250605  35704.493935\n",
       "4         No      No   785.655883  38463.495879\n",
       "...      ...     ...          ...           ...\n",
       "9995      No      No   711.555020  52992.378914\n",
       "9996      No      No   757.962918  19660.721768\n",
       "9997      No      No   845.411989  58636.156984\n",
       "9998      No      No  1569.009053  36669.112365\n",
       "9999      No     Yes   200.922183  16862.952321\n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Default = load_data(\"Default\")\n",
    "Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "3b2067b1-6761-4b73-bb43-fd4449d8aa10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>std err</th>\n",
       "      <th>z</th>\n",
       "      <th>P&gt;|z|</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td>-11.540500</td>\n",
       "      <td>0.435000</td>\n",
       "      <td>-26.544</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income</th>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>4.174</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balance</th>\n",
       "      <td>0.005600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.835</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                coef   std err       z  P>|z|\n",
       "intercept -11.540500  0.435000 -26.544    0.0\n",
       "income      0.000021  0.000005   4.174    0.0\n",
       "balance     0.005600  0.000000  24.835    0.0"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allvars = Default[['income','balance']]\n",
    "design = MS(allvars)\n",
    "Default['default'] = (Default['default'] == 'Yes').astype('int')\n",
    "X = design.fit_transform(Default)\n",
    "y = Default[\"default\"]\n",
    "model_a = sm.GLM(y, X, family=sm.families.Binomial())\n",
    "results = model_a.fit()\n",
    "summarize(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69968c0-06be-46bf-b7ec-302313720112",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*(b) Using the validation set approach, estimate the test error of this model. In order to do this, you must perform the following steps:</span>*\n",
    "\n",
    "#### <span style=\"font-family: 'NewComputerModernMath';\">&emsp; ***i.** Split the sample set into a training set and a validation set.</span>*\n",
    "#### <span style=\"font-family: 'NewComputerModernMath';\">&emsp; ***ii.** Fit a multiple logistic regression model using only the training observations.</span>*  \n",
    "#### <span style=\"font-family: 'NewComputerModernMath';\">&emsp; ***iii.** Obtain a prediction of default status for each individual in the validation set by computing the posterior probability of default for that individual, and classifying the individual to the <span style=\"color: rgb(145, 75, 40);\">default</span> category if the posterior probability is greater than 0.5.</span>*\n",
    "#### <span style=\"font-family: 'NewComputerModernMath';\">&emsp; ***iv.** Compute the validation set error, which is the fraction of the observations in the validation set that are misclassified.</span>* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "3d6734bd-4414-4641-8d29-f4591efe2386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.028800000000000048"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state =0)\n",
    "model_b = sm.GLM(y_train, X_train, family=sm.families.Binomial())\n",
    "model_b = model_b.fit()\n",
    "\n",
    "logit_pred = (model_b.predict(X_test) > 0.5).astype(int)\n",
    "acc = np.mean(logit_pred == y_test)\n",
    "1 - acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3503cb2d-5326-4ad0-b4ca-98798ed41b9f",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*(c) Repeat the process in (b) three times, using three different splits of the observations into a training set and a validation set. Comment on the results obtained.</span>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "90e73474-850d-4f81-bbc3-9f4a8b9c033f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0252\n",
      "0.023599999999999954\n",
      "0.027599999999999958\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    model_c = sm.GLM(y_train, X_train, family=sm.families.Binomial())\n",
    "    model_c = model_c.fit()\n",
    "\n",
    "    logit_pred = (model_c.predict(X_test) > 0.5).astype(int)\n",
    "    acc = np.mean(logit_pred == y_test)\n",
    "    print(1 - acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8450c865-3d11-4d37-be39-77864e8bbf61",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*(d) Now consider a logistic regression model that predicts the probability of <span style=\"color: rgb(145, 75, 40);\">default</span> using <span style=\"color: rgb(145, 75, 40);\">income</span>, <span style=\"color: rgb(145, 75, 40);\">balance</span>, and a dummy variable for <span style=\"color: rgb(145, 75, 40);\">student</span>. Estimate the test error for this model using the validation set approach. Comment on whether or not including a dummy variable for <span style=\"color: rgb(145, 75, 40);\">student</span> leads to a reduction in the test error rate.</span>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "d08a7430-89c4-4ac9-98cc-3698ac855190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.028800000000000048\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>std err</th>\n",
       "      <th>z</th>\n",
       "      <th>P&gt;|z|</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td>-10.587500</td>\n",
       "      <td>0.57300</td>\n",
       "      <td>-18.479</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income</th>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>-0.308</td>\n",
       "      <td>0.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balance</th>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>21.096</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>student</th>\n",
       "      <td>-0.684300</td>\n",
       "      <td>0.27800</td>\n",
       "      <td>-2.461</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                coef  std err       z  P>|z|\n",
       "intercept -10.587500  0.57300 -18.479  0.000\n",
       "income     -0.000003  0.00001  -0.308  0.758\n",
       "balance     0.005700  0.00000  21.096  0.000\n",
       "student    -0.684300  0.27800  -2.461  0.014"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Default['student'] = (Default['student'] == 'Yes').astype('int')\n",
    "allvars = Default[['income','balance','student']]\n",
    "design = MS(allvars)\n",
    "X = design.fit_transform(Default)\n",
    "y = Default[\"default\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state =0)\n",
    "model_d = sm.GLM(y_train, X_train, family=sm.families.Binomial())\n",
    "model_d = model_d.fit()\n",
    "\n",
    "logit_pred = (model_d.predict(X_test) > 0.5).astype(int)\n",
    "acc = np.mean(logit_pred == y_test)\n",
    "print(1 - acc)\n",
    "summarize(model_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5464ca11-db6b-4938-af10-92d057b28050",
   "metadata": {},
   "source": [
    "<span style=\"font-family: '';\"> Adding student parameter did not help tp reduce error rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202cb420-2dc0-4c0a-ba7f-89d018d9e2ac",
   "metadata": {},
   "source": [
    "### <span style=\"color: rgb(0, 105, 175);font-family: 'NewComputerModernMath';\">Q6</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54eb0c1-37a7-4ae7-a336-b16213c188c0",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\"> *We continue to consider the use of a logistic regression model to predict the probability of <span style=\"color: rgb(145, 75, 40);\">default</span> using <span style=\"color: rgb(145, 75, 40);\">income</span> and <span style=\"color: rgb(145, 75, 40);\">balance</span> on the <span style=\"color: rgb(145, 75, 40);\">Default</span> data set. In particular, we will now compute estimates for the standard errors of the <span style=\"color: rgb(145, 75, 40);\">income</span> and <span style=\"color: rgb(145, 75, 40);\">balance</span> logistic regression coefficients in two different ways: (1) using the bootstrap, and (2) using the standard formula for computing the standard errors in the <span style=\"color: rgb(145, 75, 40);\">sm.GLM()</span> function. Do not forget to set a random seed before beginning your analysis.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35669393-3435-4da0-9e40-417f6b3d4ddd",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*(a) Using the <span style=\"color: rgb(145, 75, 40);\">summarize()</span> and <span style=\"color: rgb(145, 75, 40);\">sm.GLM()</span> functions, determine the estimated standard errors for the coefficients associated with <span style=\"color: rgb(145, 75, 40);\">income</span> and <span style=\"color: rgb(145, 75, 40);\">balance</span> in a multiple logistic regression model that uses both predictors.</span>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "1ec370e9-0031-4973-a9bc-7bc799006a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.028800000000000048\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>std err</th>\n",
       "      <th>z</th>\n",
       "      <th>P&gt;|z|</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td>-11.311000</td>\n",
       "      <td>0.502000</td>\n",
       "      <td>-22.524</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income</th>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>2.765</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balance</th>\n",
       "      <td>0.005600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.171</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                coef   std err       z  P>|z|\n",
       "intercept -11.311000  0.502000 -22.524  0.000\n",
       "income      0.000016  0.000006   2.765  0.006\n",
       "balance     0.005600  0.000000  21.171  0.000"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allvars = Default[['income','balance']]\n",
    "design = MS(allvars)\n",
    "X = design.fit_transform(Default)\n",
    "y = Default[\"default\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state =0)\n",
    "model_a = sm.GLM(y_train, X_train, family=sm.families.Binomial())\n",
    "model_a = model_a.fit()\n",
    "\n",
    "logit_pred = (model_a.predict(X_test) > 0.5).astype(int)\n",
    "acc = np.mean(logit_pred == y_test)\n",
    "print(1 - acc)\n",
    "summarize(model_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e521fd-6b0b-4e04-9313-ad117f8b569f",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*b) Write a function, <span style=\"color: rgb(145, 75, 40);\">boot_fn()</span>, that takes as input the <span style=\"color: rgb(145, 75, 40);\">Default</span> data set as well as an index of the observations, and that outputs the coefficient estimates for <span style=\"color: rgb(145, 75, 40);\">income</span> and <span style=\"color: rgb(145, 75, 40);\">balance</span> in the multiple logistic regression model.</span>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "aacf49dc-6ffb-44d5-a921-d332666a2481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boot_fn(dataset):\n",
    "    X,y = dataset\n",
    "    model = sm.GLM(y, X, family=sm.families.Binomial())\n",
    "    model = model.fit()\n",
    "\n",
    "    return [model.params.iloc[1], model.params.iloc[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "0ea01f6a-9aef-400d-8acb-acda1098e072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.080897552898698e-05, 0.0056471029503164915]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boot_fn([X,y])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46dfa24-0acf-4ac0-b4b7-0d083cadb76c",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*(c) Following the bootstrap example in the lab, use your <span style=\"color: rgb(145, 75, 40);\">boot_fn()</span> function to estimate the standard errors of the logistic regression coefficients for <span style=\"color: rgb(145, 75, 40);\">income</span> and <span style=\"color: rgb(145, 75, 40);\">balance</span>.</span>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "34fe94c4-25e4-4cb9-9e1b-b1bb873b5688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(X, y, boot_size):\n",
    "    if boot_size is None or boot_size == 0:\n",
    "        return [X, y]\n",
    "\n",
    "    # Concatenate X and y along the columns\n",
    "    data = pd.concat([X, y], axis=1)\n",
    "    \n",
    "    # Perform bootstrap sampling with replacement\n",
    "    bootstrapped_data = data.sample(n=boot_size, replace=True)\n",
    "    \n",
    "    # Drop the last column (instead of specifically \"default\")\n",
    "    X_bootstrapped = bootstrapped_data.drop(columns=[bootstrapped_data.columns[-1]])\n",
    "    \n",
    "    # Extract the last column as y\n",
    "    y_bootstrapped = bootstrapped_data[bootstrapped_data.columns[-1]]\n",
    "\n",
    "    return [X_bootstrapped, y_bootstrapped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "acb2a21f-ad0c-4173-9ad1-464337e5a3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.000021\n",
      "1    0.005662\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "n=1000\n",
    "coefficients = [] \n",
    "\n",
    "for i in range(0,n):\n",
    "    coef_i = boot_fn(bootstrap(X,y, len(X))) \n",
    "    coefficients.append(coef_i) \n",
    "\n",
    "mean_coefs = pd.DataFrame(coefficients).mean()\n",
    "print(mean_coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "44604e99-8926-4a7d-9696-3ec2954434f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Errors of the Coefficients:\n",
      "0    0.000005\n",
      "1    0.000228\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "coefficients_df = pd.DataFrame(coefficients)\n",
    "standard_errors = coefficients_df.std()\n",
    "\n",
    "print(\"Standard Errors of the Coefficients:\")\n",
    "print(standard_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4521dc1-311a-4240-9873-6c527a947370",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*(d) Comment on the estimated standard errors obtained using the <span style=\"color: rgb(145, 75, 40);\">sm.GLM()</span> function and using the bootstrap.</span>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "af663be0-fb4f-4dcd-92a4-a36f63db7b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interval for coefficient of Income is: [ 1.6016902282734988e-05 ,  2.6025070641038296e-05\n",
      "Interval for coefficient of balance is: [ 0.005433597290406233 ,  0.005890274503462617\n"
     ]
    }
   ],
   "source": [
    "print(\"Interval for coefficient of Income is: [\",mean_coefs[0]-standard_errors[0],\", \",mean_coefs[0]+standard_errors[0])\n",
    "print(\"Interval for coefficient of balance is: [\",mean_coefs[1]-standard_errors[1],\", \",mean_coefs[1]+standard_errors[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ecbf90-3d9a-4c4b-b514-ecba09815d8d",
   "metadata": {},
   "source": [
    "### <span style=\"color: rgb(0, 105, 175);font-family: 'NewComputerModernMath';\">Q7</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ebbf3e-4889-4f00-b5bc-d63f9d5eee23",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\"> *In Sections <span style=\"color: rgb(0, 0, 255);\">5.1.2</span> and <span style=\"color: rgb(0, 0, 255);\">5.1.3</span>, we saw that the <span style=\"color: rgb(145, 75, 40);\">cross_validate()</span> function can be used in order to compute the LOOCV test error estimate. Alternatively, one could compute those quantities using just <span style=\"color: rgb(145, 75, 40);\">sm.GLM()</span> and the <span style=\"color: rgb(145, 75, 40);\">predict()</span> method of the fitted model within a for loop. You will now take this approach in order to compute the LOOCV error for a simple logistic regression model on the <span style=\"color: rgb(145, 75, 40);\">Weekly</span> data set. Recall that in the context of classification problems, the LOOCV error is given in (<span style=\"color: rgb(0, 0, 255);\">5.4</span>).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b1a456-656c-4def-bf54-af8f2f92db44",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*(a) Fit a logistic regression model that predicts <span style=\"color: rgb(145, 75, 40);\">Direction</span> using <span style=\"color: rgb(145, 75, 40);\">Lag1</span> and <span style=\"color: rgb(145, 75, 40);\">Lag2</span>.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "79d4a0be-38cc-4265-8050-0a2ea4f81eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Today</th>\n",
       "      <th>Direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>-3.484</td>\n",
       "      <td>0.154976</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.148574</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>0.159837</td>\n",
       "      <td>3.514</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990</td>\n",
       "      <td>3.514</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>0.161630</td>\n",
       "      <td>0.712</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990</td>\n",
       "      <td>0.712</td>\n",
       "      <td>3.514</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.153728</td>\n",
       "      <td>1.178</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>2010</td>\n",
       "      <td>-0.861</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-2.173</td>\n",
       "      <td>3.599</td>\n",
       "      <td>0.015</td>\n",
       "      <td>3.205160</td>\n",
       "      <td>2.969</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>2010</td>\n",
       "      <td>2.969</td>\n",
       "      <td>-0.861</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-2.173</td>\n",
       "      <td>3.599</td>\n",
       "      <td>4.242568</td>\n",
       "      <td>1.281</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>2010</td>\n",
       "      <td>1.281</td>\n",
       "      <td>2.969</td>\n",
       "      <td>-0.861</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-2.173</td>\n",
       "      <td>4.835082</td>\n",
       "      <td>0.283</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>2010</td>\n",
       "      <td>0.283</td>\n",
       "      <td>1.281</td>\n",
       "      <td>2.969</td>\n",
       "      <td>-0.861</td>\n",
       "      <td>0.043</td>\n",
       "      <td>4.454044</td>\n",
       "      <td>1.034</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>2010</td>\n",
       "      <td>1.034</td>\n",
       "      <td>0.283</td>\n",
       "      <td>1.281</td>\n",
       "      <td>2.969</td>\n",
       "      <td>-0.861</td>\n",
       "      <td>2.707105</td>\n",
       "      <td>0.069</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1089 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year   Lag1   Lag2   Lag3   Lag4   Lag5    Volume  Today Direction\n",
       "0     1990  0.816  1.572 -3.936 -0.229 -3.484  0.154976 -0.270      Down\n",
       "1     1990 -0.270  0.816  1.572 -3.936 -0.229  0.148574 -2.576      Down\n",
       "2     1990 -2.576 -0.270  0.816  1.572 -3.936  0.159837  3.514        Up\n",
       "3     1990  3.514 -2.576 -0.270  0.816  1.572  0.161630  0.712        Up\n",
       "4     1990  0.712  3.514 -2.576 -0.270  0.816  0.153728  1.178        Up\n",
       "...    ...    ...    ...    ...    ...    ...       ...    ...       ...\n",
       "1084  2010 -0.861  0.043 -2.173  3.599  0.015  3.205160  2.969        Up\n",
       "1085  2010  2.969 -0.861  0.043 -2.173  3.599  4.242568  1.281        Up\n",
       "1086  2010  1.281  2.969 -0.861  0.043 -2.173  4.835082  0.283        Up\n",
       "1087  2010  0.283  1.281  2.969 -0.861  0.043  4.454044  1.034        Up\n",
       "1088  2010  1.034  0.283  1.281  2.969 -0.861  2.707105  0.069        Up\n",
       "\n",
       "[1089 rows x 9 columns]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Weekly = load_data(\"Weekly\")\n",
    "Weekly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "4c745e70-e040-47f1-8cab-0e8e1cfd2a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>std err</th>\n",
       "      <th>z</th>\n",
       "      <th>P&gt;|z|</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td>0.2212</td>\n",
       "      <td>0.061</td>\n",
       "      <td>3.599</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag1</th>\n",
       "      <td>-0.0387</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-1.477</td>\n",
       "      <td>0.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag2</th>\n",
       "      <td>0.0602</td>\n",
       "      <td>0.027</td>\n",
       "      <td>2.270</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             coef  std err      z  P>|z|\n",
       "intercept  0.2212    0.061  3.599  0.000\n",
       "Lag1      -0.0387    0.026 -1.477  0.140\n",
       "Lag2       0.0602    0.027  2.270  0.023"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allvars = Weekly[['Lag1','Lag2']]\n",
    "design = MS(allvars)\n",
    "X = design.fit_transform(Weekly)\n",
    "y = (Weekly[\"Direction\"] == \"Up\").astype(int)\n",
    "\n",
    "model_a = sm.GLM(y, X, family=sm.families.Binomial())\n",
    "model_a = model_a.fit()\n",
    "summarize(model_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1e707f-ffe6-4098-b968-7c344c38b548",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*(b) Fit a logistic regression model that predicts <span style=\"color: rgb(145, 75, 40);\">Direction</span> using <span style=\"color: rgb(145, 75, 40);\">Lag1</span> and <span style=\"color: rgb(145, 75, 40);\">Lag2</span> <i>using all but the first observation.</i></span>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "2fa13de6-6cbc-4440-a4c5-472d7157c27b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>std err</th>\n",
       "      <th>z</th>\n",
       "      <th>P&gt;|z|</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td>0.2232</td>\n",
       "      <td>0.061</td>\n",
       "      <td>3.630</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag1</th>\n",
       "      <td>-0.0384</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-1.466</td>\n",
       "      <td>0.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag2</th>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.027</td>\n",
       "      <td>2.291</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             coef  std err      z  P>|z|\n",
       "intercept  0.2232    0.061  3.630  0.000\n",
       "Lag1      -0.0384    0.026 -1.466  0.143\n",
       "Lag2       0.0608    0.027  2.291  0.022"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_b = sm.GLM(y[1:], X[1:], family=sm.families.Binomial())\n",
    "model_b = model_b.fit()\n",
    "summarize(model_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116712fe-9380-4441-88b7-3520c3b46e15",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*(c) Use the model from (b) to predict the direction of the first observation. You can do this by predicting that the first observation will go up if $ P(\\text{Direction} = \\text{\"Up\"} \\mid \\text{Lag1}, \\text{Lag2}) > 0.5 $. Was this observation correctly classified?</span>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "508ad969-f30f-4483-a97a-bff732c59e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  1  | Actual:  0\n"
     ]
    }
   ],
   "source": [
    "pred = model_b.predict(X[:1])\n",
    "print(\"Prediction: \", (pred > 0.5).astype(int)[0], \" | Actual: \",y[:1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189c7660-282f-4a4a-854f-9d0cb3f25d04",
   "metadata": {},
   "source": [
    "<span style=\"font-family: '';\"> Prediction is wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0860f72e-c240-4609-b0b6-980bff0ccbf6",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*(d) Write a for loop from $ i = 1 $ to $ i = n $, where $ n $ is the number of observations in the data set, that performs each of the following steps:</span>*\n",
    "\n",
    "#### <span style=\"font-family: 'NewComputerModernMath';\">&emsp; ***i.** Fit a logistic regression model using all but the $ i $th observation to predict <span style=\"color: rgb(145, 75, 40);\">Direction</span> using <span style=\"color: rgb(145, 75, 40);\">Lag1</span> and #### <span style=\"color: rgb(145, 75, 40);\">Lag2</span>.*  \n",
    "#### <span style=\"font-family: 'NewComputerModernMath';\">&emsp; ***ii.** Compute the posterior probability of the market moving up for the $ i $th observation.</span>*  \n",
    "#### <span style=\"font-family: 'NewComputerModernMath';\">&emsp; ***iii.** Use the posterior probability for the $ i $th observation in order to predict whether or not the market moves up.</span>*  \n",
    "#### <span style=\"font-family: 'NewComputerModernMath';\">&emsp; ***iv.** Determine whether or not an error was made in predicting the direction for the $ i $th observation. If an error was made, then indicate this as a 1, and otherwise indicate it as a 0.</span>*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "a287394b-29f9-480b-addf-c01b26468105",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_count = 0\n",
    "for i in range(len(X)):\n",
    "    one_out  = ~X.index.isin([i])\n",
    "    model_c = sm.GLM(y[one_out], X[one_out], family=sm.families.Binomial())\n",
    "    model_c = model_c.fit()\n",
    "\n",
    "    error_count += 1 if ((model_c.predict(X[i:i+1]) > 0.5).astype(int)[i] != y[i:i+1][i]) else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521640ac-2f37-480a-b0e3-cdcef824280a",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*(e) Take the average of the $ n $ numbers obtained in (d)iv in order to obtain the LOOCV estimate for the test error. Comment on the results.</span>*\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "27128f26-c069-4998-ab5d-2f8a1a7c3619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "490 / 1089  =  0.44995408631772266\n"
     ]
    }
   ],
   "source": [
    "print(error_count,\"/\",len(X), \" = \", error_count/len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b24126-9062-4f35-a69b-2c2c116d6f98",
   "metadata": {},
   "source": [
    "### <span style=\"color: rgb(0, 105, 175);font-family: 'NewComputerModernMath';\">Q8</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f26d5cc-d523-41e6-8477-399af3a34ae6",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*We will now perform cross-validation on a simulated data set.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773656b1-a8fd-49ee-b6c2-6ea838ac00ac",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*(a) Generate a simulated data set as follows:</span>*\n",
    "\n",
    "```python\n",
    "rng = np.random.default_rng(1)\n",
    "x = rng.normal(size=100)\n",
    "y = x - 2 * x**2 + rng.normal(size=100)\n",
    "```\n",
    "\n",
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*In this data set, what is 𝑛 and what is 𝑝? Write out the model used to generate the data in equation form.</span>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "f2835e1e-2bfe-4ea6-987c-c81e281b3b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(1)\n",
    "x = rng.normal(size=100)\n",
    "y = x - 2 * x**2 + rng.normal(size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ca1e48-f3fc-4195-b317-300ebd000ff1",
   "metadata": {},
   "source": [
    "<span style=\"font-family: '';\"> n = 100 | p = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b77ed88-146b-40d2-b871-91a7825f75cf",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*(b) Create a scatterplot of 𝑋 against 𝑌. Comment on what you find.</span>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "0854e8c3-17bb-493e-9c14-3bd222eb1b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x314b22e90>"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35272613-e013-4f23-80e4-4cb74f742a32",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*(c) Set a random seed, and then compute the LOOCV errors that result from fitting the following four models using least squares:</span>*\n",
    "\n",
    "#### **i.** $ Y = \\beta_0 + \\beta_1 X + \\epsilon $\n",
    "\n",
    "#### **ii.** $ Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\epsilon $\n",
    "\n",
    "#### **iii.** $ Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\beta_3 X^3 + \\epsilon $\n",
    "\n",
    "#### **iv.** $ Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\beta_3 X^3 + \\beta_4 X^4 + \\epsilon $.\n",
    "\n",
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*Note you may find it helpful to use the <span style=\"color: rgb(145, 75, 40);\">data.frame()</span> function to create a single data set containing both 𝑋 and 𝑌.</span>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "da453f30-2c3f-4ebf-97d2-5c7cd6327988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.345584</td>\n",
       "      <td>-0.544554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.821618</td>\n",
       "      <td>0.333950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.330437</td>\n",
       "      <td>-0.013532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.303157</td>\n",
       "      <td>-4.030442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.905356</td>\n",
       "      <td>0.484861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-2.250854</td>\n",
       "      <td>-14.001012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-0.138655</td>\n",
       "      <td>0.932532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.033000</td>\n",
       "      <td>0.198928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-1.425349</td>\n",
       "      <td>-4.940183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.332814</td>\n",
       "      <td>-0.953841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           X          y\n",
       "0   0.345584  -0.544554\n",
       "1   0.821618   0.333950\n",
       "2   0.330437  -0.013532\n",
       "3  -1.303157  -4.030442\n",
       "4   0.905356   0.484861\n",
       "..       ...        ...\n",
       "95 -2.250854 -14.001012\n",
       "96 -0.138655   0.932532\n",
       "97  0.033000   0.198928\n",
       "98 -1.425349  -4.940183\n",
       "99  0.332814  -0.953841\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "np.random.seed(5)\n",
    "loo = LeaveOneOut()\n",
    "df = pd.DataFrame({'X':x, 'y':y})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "83a729cd-94de-4a38-8e51-009d367b5ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loocv_test(df,seed,degree):\n",
    "    loo_errors = {}\n",
    "    max_degree = 4\n",
    "    X = df['X'].values.reshape(-1, 1)  # Ensure X is a 2D array\n",
    "    y = df['y'].values\n",
    "    np.random.seed(seed)\n",
    "    for degree in range(1, max_degree + 1):\n",
    "        poly = PolynomialFeatures(degree=degree)\n",
    "        X_poly = poly.fit_transform(X)  # Transform X into polynomial features\n",
    "            \n",
    "        errors = []\n",
    "            \n",
    "        for train_index, test_index in loo.split(X_poly):\n",
    "            X_train, X_test = X_poly[train_index], X_poly[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            \n",
    "            # Add a constant term for the intercept in OLS model\n",
    "            X_train_const = sm.add_constant(X_train)\n",
    "            X_test_const = sm.add_constant(X_test)\n",
    "            \n",
    "            # Fit the OLS model\n",
    "            model = sm.OLS(y_train, X_train_const)\n",
    "            results = model.fit()\n",
    "            \n",
    "            # Predict and calculate the error\n",
    "            y_pred = results.predict(X_test_const)\n",
    "            error = mean_squared_error(y_test, y_pred)\n",
    "            errors.append(error)\n",
    "        \n",
    "        loo_errors[degree] = np.mean(errors)\n",
    "    print(loo_errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "40076ba2-00de-49a1-98d2-771b8eab3dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 6.633029839181984, 2: 1.1229368563419688, 3: 1.3017965489358887, 4: 1.332394269417942}\n"
     ]
    }
   ],
   "source": [
    "loocv_test(df,23,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283d0a2a-ab12-4093-a390-871ae047a31c",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*(d) Repeat (c) using another random seed, and report your results. Are your results the same as what you got in (c)? Why?</span>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "6cd651e6-5e04-49e7-b566-70df9bb8a86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 6.633029839181984, 2: 1.1229368563419688, 3: 1.3017965489358887, 4: 1.332394269417942}\n"
     ]
    }
   ],
   "source": [
    "loocv_test(df,44,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fe154d-1a97-44a9-bba8-8a4b4d314e12",
   "metadata": {},
   "source": [
    "<span style=\"font-family: '';\"> Results are exactly same because LOOCV use only one sample to test, so even randomness is changed, while the order changes, operations are same. Therefore, results will be same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a181eb-437a-499d-93b9-7be4fa142031",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*(e) Which of the models in (c) had the smallest LOOCV error? Is this what you expected? Explain your answer.</span>*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56f5247-5bfc-4f1b-bec5-e04b8aad85d8",
   "metadata": {},
   "source": [
    "<span style=\"font-family: '';\"> p=2 (x**2) has the smallest error. We expected that because we know that the equation for y was $y = x - 2x^2 + \\epsilon$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61b6d8b-0bba-465e-a7bf-4327641d362e",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*(f) Comment on the statistical significance of the coefficient estimates that result from fitting each of the models in (c) using least squares. Do these results agree with the conclusions drawn based on the cross-validation results?</span>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "0606ef56-65dc-4d9f-89cf-3b207d10a993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>std err</th>\n",
       "      <th>t</th>\n",
       "      <th>P&gt;|t|</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>0.1008</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1</th>\n",
       "      <td>0.9050</td>\n",
       "      <td>0.205</td>\n",
       "      <td>4.423</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2</th>\n",
       "      <td>-2.5059</td>\n",
       "      <td>0.221</td>\n",
       "      <td>-11.336</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x3</th>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x4</th>\n",
       "      <td>0.1042</td>\n",
       "      <td>0.045</td>\n",
       "      <td>2.309</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         coef  std err       t  P>|t|\n",
       "const  0.1008    0.136   0.743  0.460\n",
       "x1     0.9050    0.205   4.423  0.000\n",
       "x2    -2.5059    0.221 -11.336  0.000\n",
       "x3     0.0338    0.073   0.466  0.642\n",
       "x4     0.1042    0.045   2.309  0.023"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df['X'].values.reshape(-1, 1)\n",
    "y = df['y'].values\n",
    "poly = PolynomialFeatures(degree=4)\n",
    "X_poly = poly.fit_transform(X)\n",
    "X_const = sm.add_constant(X_poly)\n",
    "\n",
    "model_f = sm.OLS(y,X_const).fit()\n",
    "\n",
    "summarize(model_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963eb394-49d2-4c26-bd48-2c2777fd647e",
   "metadata": {},
   "source": [
    "<span style=\"font-family: '';\"> The model fitting with p=4 shows that $x^3$ and $x^4$ cannot pass the null hypothesis due to the p-values. Only $x$ and $x^2$ coefficients have significance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b88739d-986a-42db-8aba-c97bd9c24a8d",
   "metadata": {},
   "source": [
    "### <span style=\"color: rgb(0, 105, 175);font-family: 'NewComputerModernMath';\">Q9</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e3fdbb-5e23-40b4-a997-ad6d4623da4c",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*We will now consider the <span style=\"color: rgb(145, 75, 40);\">Boston</span> housing data set, from the <span style=\"color: rgb(145, 75, 40);\">ISLP</span> library.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5551c7-502e-4a62-95d7-6a8997baccbf",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*(a) Based on this data set, provide an estimate for the population mean of <span style=\"color: rgb(145, 75, 40);\">medv</span>. Call this estimate $ \\hat{\\mu} $.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "22ef6d67-1f8f-4bc7-a1cc-3ac0f492be16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.532806324110677"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Boston = load_data(\"Boston\")\n",
    "mu = Boston.medv.mean()\n",
    "mu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3ef183-2b01-4fea-b1e9-ab83b5be0e18",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*(b) Provide an estimate of the standard error of $ \\hat{\\mu} $. Interpret this result.</span>*\n",
    "\n",
    "#### <span style=\"font-style: italic;\">*Hint: We can compute the standard error of the sample mean by dividing the sample standard deviation by the square root of the number of observations.</span>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "0d4d7794-7c9d-4b6b-9223-69a0d77ff09f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4088611474975351"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SE = Boston.medv.std() / np.sqrt(len(Boston))\n",
    "SE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f246405-7c02-4187-aee4-923b47cf5672",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*(c) Now estimate the standard error of $ \\hat{\\mu} $ using the bootstrap. How does this compare to your answer from (b)?</span>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "ea93d75a-2063-4b82-8c93-b093fbecb959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4067956213735371"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mus = [Boston.medv.sample(n = len(Boston), replace=True).mean() for _ in range(10000)]\n",
    "np.std(mus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273b7d3e-eb7f-4830-a9ab-1ffab2d98d24",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*(d) Based on your bootstrap estimate from (c), provide a 95% confidence interval for the mean of <span style=\"color: rgb(145, 75, 40);\">medv</span>. Compare it to the results obtained by using <span style=\"color: rgb(145, 75, 40);\">Boston['medv'].std()</span> and the two standard error rule (<span style=\"color: rgb(0, 0, 255);\">3.9</span>).*  \n",
    "\n",
    "#### <span style=\"font-style: italic;\">*Hint: You can approximate a 95% confidence interval using the formula $[ \\hat{\\mu} - 2SE(\\hat{\\mu}), \\hat{\\mu} + 2SE(\\hat{\\mu}) ]$.</span>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "12c4ece1-25a7-4c85-9f64-3ee1103be5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.719215081363604 23.34639756685775\n"
     ]
    }
   ],
   "source": [
    "SE = np.std(mus)\n",
    "print(mu - 2*SE, mu + 2*SE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "cee204d6-5c77-4e00-92fe-bb9e98309915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.138598149351036 40.92701449887032\n"
     ]
    }
   ],
   "source": [
    "print(Boston['medv'].mean() - 2*Boston['medv'].std(), Boston['medv'].mean() + 2*Boston['medv'].std()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158c9f7b-b130-433a-9397-f18df8a493e4",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*(e) Based on this data set, provide an estimate, $ \\hat{\\mu}_{med} $, for the median value of <span style=\"color: rgb(145, 75, 40);\">medv</span> in the population.</span>* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "8b8a2a77-33de-4393-8d12-ac025a7b31fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.2"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Boston.medv.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b718e468-8ced-4632-af45-5a7f467c1a32",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*(f) We now would like to estimate the standard error of $ \\hat{\\mu}_{med} $. Unfortunately, there is no simple formula for computing the standard error of the median. Instead, estimate the standard error of the median using the bootstrap. Comment on your findings.</span>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "41d5b8d4-2a47-4956-94db-2f1ec7a6dea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37682039219633506"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medians = [Boston.medv.sample(n = len(Boston), replace=True).median() for _ in range(10000)]\n",
    "np.std(medians)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2656d76b-4a3b-4e0d-9dfd-7727c7804c8e",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\">*(g) Based on this data set, provide an estimate for the tenth percentile of <span style=\"color: rgb(145, 75, 40);\">medv</span> in Boston census tracts. Call this quantity $ \\hat{\\mu}_{0.1} $. (You can use the <span style=\"color: rgb(145, 75, 40);\">np.percentile()</span> function.)</span>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "11f3ebae-e737-4186-a22d-7e044d05ec55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.75"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu10 = np.percentile(Boston.medv, 10)\n",
    "mu10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc2ea90-c3b0-4c95-a154-d64b2cccaa66",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'NewComputerModernMath';\">(*h) Use the bootstrap to estimate the standard error of $ \\hat{\\mu}_{0.1} $. Comment on your findings.</span>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "a9082d09-e692-4695-86d4-8836842801e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49683440611535745"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu10s = [np.percentile(Boston.medv.sample(n = len(Boston), replace=True),10) for _ in range(10000)]\n",
    "np.std(mu10s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
